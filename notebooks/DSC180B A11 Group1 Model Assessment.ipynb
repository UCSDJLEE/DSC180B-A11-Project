{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32e50f37",
   "metadata": {},
   "source": [
    "## DSC180B Group11 Model Assessment\n",
    "\n",
    "#### This notebook demonstrates the model training and assessment by displaying learning curve(training&validation) and resolution plot for test sets.\n",
    "\n",
    "### CAVEAT: Make sure you run `python3 run.py test` prior to reviewing this notebook as some contents in the notebook reflect the result from initial model fitting process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62441903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "import torch.nn as nn\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, ReLU, BatchNorm1d, Flatten, Module\n",
    "from torch_scatter import scatter_mean\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.data import DataListLoader, Batch\n",
    "device =  torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import yaml\n",
    "\n",
    "sys.path.insert(0, '../src/')\n",
    "from model import Net\n",
    "from GraphDataset import GraphDataset\n",
    "from load_data import path_generator, random_test_path_generator\n",
    "\n",
    "ROOT = \"/home/h8lee/DSC180B-A11-Project\"\n",
    "CONFIG ='conf/reg_defs.yml'\n",
    "batch_size = 32\n",
    "\n",
    "with open(os.path.join(ROOT, CONFIG)) as file:\n",
    "    # The FullLoader parameter handles the conversion from YAML\n",
    "    # scalar values to Python the dictionary format\n",
    "    definitions = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "features = definitions['features']\n",
    "spectators = definitions['spectators']\n",
    "labels = definitions['labels']\n",
    "\n",
    "nfeatures = definitions['nfeatures']\n",
    "nlabels = definitions['nlabels']\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bb9db6",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40de114e",
   "metadata": {},
   "source": [
    "### Model Assessment -- Learning curve on <font color=blue>training</font> & <font color=orange>validation set</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb773b89",
   "metadata": {},
   "source": [
    " Below is the learning curve of our NN jet mass regressor model, collected during model training process. The model is trained on multiple signal and QCD jet data along with the validation set used to prevent overfitting and enforce early stopping of training epochs. By default, the training epoch is set to $100$, and early stopping is implemented only to be enforced after at least 30 epochs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762254fa",
   "metadata": {},
   "source": [
    "<img src='learning_curve.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd6427c",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65cda4a",
   "metadata": {},
   "source": [
    "### Model Assessment -- Resolution plot on <font color='green'>test set</font>\n",
    "\n",
    "We will now evaluate the performance of our NN regressor model by making predictions on unseen jet data. After loading the fitted weights, model will predict the ground-truth jet mass in test set and subsequently, resolutions of each of the predictions will get calculated. After all predictions, we will sketch resolution plot to measure how well the predictions align with their target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faf43d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(items): return Batch.from_data_list(sum(items, []))\n",
    "\n",
    "test_files = random_test_path_generator()\n",
    "test_dir_path = os.path.join(ROOT, 'test_data')\n",
    "test_graph_dataset = GraphDataset(test_dir_path, features, labels, spectators, n_events=1000, n_events_merge=1, \n",
    "                         file_names=test_files)\n",
    "\n",
    "test_loader = DataListLoader(test_graph_dataset, batch_size=batch_size, \n",
    "                             pin_memory=True, shuffle=True)\n",
    "test_loader.collate_fn = collate\n",
    "test_samples = len(test_graph_dataset)\n",
    "\n",
    "test_p = tqdm(enumerate(test_loader), total=test_samples/batch_size)\n",
    "test_lst = []\n",
    "net = Net().to(device)\n",
    "modpath = os.path.join(ROOT, 'simplenetwork_best.pt')\n",
    "\n",
    "# Retrieve the model weights that produced smallest validation loss\n",
    "net.load_state_dict(torch.load(modpath));\n",
    "net.eval();\n",
    "with torch.no_grad():\n",
    "    for k, tdata in test_p:\n",
    "        tdata = tdata.to(device) # Moving data to memory\n",
    "        y = tdata.y # Retrieving target variable\n",
    "        tpreds = net(tdata.x, tdata.batch) \n",
    "        loss_t = (tpreds.float() - y.float()) / (y.float())\n",
    "        loss_t_np = loss_t.cpu().numpy()\n",
    "        loss = loss_t_np.ravel().tolist()\n",
    "        test_lst+=loss\n",
    "        \n",
    "        \n",
    "test_masked = np.ma.masked_invalid(test_lst).tolist()\n",
    "test_resolution = [x for x in test_masked if x is not None]\n",
    "\n",
    "avg_resolution = np.average(test_resolution)\n",
    "std_resolution = np.std(test_resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c230e1ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = fig.gca()\n",
    "\n",
    "_ = sns.histplot(test_resolution, stat='frequency',\n",
    "            color='lightgreen', ax=ax, bins=50,\n",
    "                label=f'NN regressor mass resolution mean={avg_resolution:.4}, std={std_resolution:.4}')\n",
    "\n",
    "_ = ax.legend(frameon=True, prop={'size':15})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaaa875",
   "metadata": {},
   "source": [
    "Test resolution we calculate from our test data form a cluster on a left-hand side with couple outliers stretching to the right-hand side, causing skewness in the distribution of test resolution. To mitigate the right-skew, we can log-scale the resolution to reshape the distribution closer to normal shape. Let's demonstrate below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f8fc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_resolution = [np.sqrt(x) for x in test_resolution]\n",
    "avg_log_resolution = np.average(log_resolution)\n",
    "std_log_resolution = np.std(log_resolution)\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = fig.gca()\n",
    "\n",
    "_ = sns.histplot(log_resolution, stat='frequency',\n",
    "            color='darkgreen', ax=ax, bins=50,\n",
    "                label=f'NN regressor mass log-scaled resolution mean={avg_log_resolution:.4}, std={std_log_resolution:.4}')\n",
    "\n",
    "\n",
    "_ = ax.legend(frameon=True, prop={'size':15})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
